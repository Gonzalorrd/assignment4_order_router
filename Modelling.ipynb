{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13adc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cluster_features import ClusterFeatureAdder\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f9f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GLOBALS\n",
    "\n",
    "# Paths to data (adjust to your folder structure)\n",
    "EXEC_PATH = \"./assignment 3/execs_from_fix.csv\"\n",
    "QUOTES_PATH = \"./assignment 4/quotes_2025-09-10_small.csv.gz\"\n",
    "\n",
    "# Optional: limit to a subset of tickers during development\n",
    "KEEP_TICKERS: Optional[List[str]] = [\n",
    "    \"AAPL\", \"MSFT\", \"NVDA\",\n",
    "    \"BRK.B\", \"HXHX\", \"SFHG\", \"DIDIY\",\n",
    "    \"INEO\", \"THH\", \"FMCC\", \"LKNCY\", \"IVFH\"\n",
    "]\n",
    "\n",
    "# Market hours filter\n",
    "MARKET_OPEN = pd.to_datetime(\"09:30\").time()\n",
    "MARKET_CLOSE = pd.to_datetime(\"16:00\").time()\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Feature and target names used for modeling\n",
    "FEATURE_COLS = [\n",
    "    \"side\",        # 1 = buy, other values = sell\n",
    "    \"order_qty\",\n",
    "    \"limit_price\",\n",
    "    \"bid_price\",\n",
    "    \"ask_price\",\n",
    "    \"bid_size\",\n",
    "    \"ask_size\",\n",
    "]\n",
    "\n",
    "TARGET_COL = \"price_improvement\"\n",
    "GROUP_COL = \"exchange\"  # train one model per exchange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b331217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DATA LOADING FUNCTIONS\n",
    "\n",
    "def load_quotes(path: str, tickers: Optional[List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"Load quotes file in chunks, filter by tickers and market hours.\"\"\"\n",
    "    dtypes = {\n",
    "        \"ticker\":    \"string\",\n",
    "        \"bid_price\": \"float32\",\n",
    "        \"ask_price\": \"float32\",\n",
    "        \"bid_size\":  \"int32\",\n",
    "        \"ask_size\":  \"int32\",\n",
    "    }\n",
    "\n",
    "    chunks: List[pd.DataFrame] = []\n",
    "    chunk_size = 1_000_000\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "        path,\n",
    "        compression=\"gzip\",\n",
    "        dtype=dtypes,\n",
    "        low_memory=False,\n",
    "        chunksize=chunk_size,\n",
    "    ):\n",
    "        if tickers is not None:\n",
    "            chunk = chunk[chunk[\"ticker\"].isin(tickers)]\n",
    "\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # Convert timestamp to datetime\n",
    "        chunk[\"sip_timestamp\"] = pd.to_datetime(\n",
    "            chunk[\"sip_timestamp\"],\n",
    "            unit=\"ns\",\n",
    "            errors=\"coerce\",\n",
    "        )\n",
    "\n",
    "        # Keep only regular market hours\n",
    "        t = chunk[\"sip_timestamp\"].dt.time\n",
    "        chunk = chunk[(t >= MARKET_OPEN) & (t <= MARKET_CLOSE)]\n",
    "\n",
    "        if not chunk.empty:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    if chunks:\n",
    "        quotes = pd.concat(chunks, ignore_index=True)\n",
    "    else:\n",
    "        quotes = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"ticker\", \"sip_timestamp\",\n",
    "                \"bid_price\", \"ask_price\",\n",
    "                \"bid_size\", \"ask_size\",\n",
    "                \"bid_exchange\", \"ask_exchange\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return quotes\n",
    "\n",
    "\n",
    "def load_executions(path: str, tickers: Optional[List[str]]) -> pd.DataFrame:\n",
    "    \"\"\"Load executions from execs_from_fix.csv and filter by tickers and market hours.\"\"\"\n",
    "    dtypes = {\n",
    "        \"order_id\":         \"string\",\n",
    "        \"symbol\":           \"string\",\n",
    "        \"side\":             \"int8\",\n",
    "        \"order_qty\":        \"int32\",\n",
    "        \"limit_price\":      \"float32\",\n",
    "        \"execution_price\":  \"float32\",\n",
    "        \"exchange\":         \"string\",\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        dtype=dtypes,\n",
    "        parse_dates=[\"order_time\", \"execution_time\"],\n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False,\n",
    "    )\n",
    "\n",
    "    if tickers is not None:\n",
    "        df = df[df[\"symbol\"].isin(tickers)]\n",
    "\n",
    "    # Keep only regular market hours based on order time\n",
    "    t = df[\"order_time\"].dt.time\n",
    "    df = df[(t >= MARKET_OPEN) & (t <= MARKET_CLOSE)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def attach_quotes(executions: pd.DataFrame, quotes: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Attach the most recent quote at or before execution_time for each symbol.\"\"\"\n",
    "    # Sort by time first, then by symbol, as required by merge_asof\n",
    "    executions.sort_values([\"execution_time\", \"symbol\"], inplace=True)\n",
    "    quotes.sort_values([\"sip_timestamp\", \"ticker\"], inplace=True)\n",
    "\n",
    "    merged = pd.merge_asof(\n",
    "        executions,\n",
    "        quotes,\n",
    "        left_on=\"execution_time\",\n",
    "        right_on=\"sip_timestamp\",\n",
    "        left_by=\"symbol\",\n",
    "        right_by=\"ticker\",\n",
    "        direction=\"backward\",\n",
    "        allow_exact_matches=True,\n",
    "    )\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. FEATURE ENGINEERING\n",
    "def add_price_improvement(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Add price_improvement column in place.\n",
    "\n",
    "    For buys (side == 1): improvement = ask_price - execution_price\n",
    "    For sells:           improvement = execution_price - bid_price\n",
    "\n",
    "    Positive values mean better-than-NBBO execution.\n",
    "    \"\"\"\n",
    "    is_buy = df[\"side\"] == 1\n",
    "\n",
    "    ref_price = np.where(is_buy, df[\"ask_price\"], df[\"bid_price\"])\n",
    "    improvement = np.where(\n",
    "        is_buy,\n",
    "        ref_price - df[\"execution_price\"],   # buy: smaller exec price better\n",
    "        df[\"execution_price\"] - ref_price,   # sell: higher exec price better\n",
    "    )\n",
    "\n",
    "    df[TARGET_COL] = improvement.astype(\"float32\")\n",
    "\n",
    "\n",
    "def prepare_model_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop rows with missing values in features or target (in place).\"\"\"\n",
    "    cols_needed = FEATURE_COLS + [TARGET_COL, GROUP_COL]\n",
    "    df.dropna(subset=cols_needed, inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42ab9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. PIPELINES & TRAINING LOGIC\n",
    "\n",
    "def make_model_candidates(random_state: int = RANDOM_SEED) -> Dict[str, Tuple[Pipeline, List[Dict]]]:\n",
    "    \"\"\"Define candidate pipelines and their hyperparameter grids.\n",
    "\n",
    "    Returns:\n",
    "        A dict model_name -> (pipeline, param_grid_list)\n",
    "        where param_grid_list is passed directly to GridSearchCV.\n",
    "    \"\"\"\n",
    "    candidates: Dict[str, Tuple[Pipeline, List[Dict]]] = {}\n",
    "\n",
    "    # 1) Linear regression baseline\n",
    "    linear_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", LinearRegression()),\n",
    "        ]\n",
    "    )\n",
    "    linear_grid = [{}]  # no hyperparameters to tune\n",
    "\n",
    "    candidates[\"linear\"] = (linear_pipe, linear_grid)\n",
    "\n",
    "    # 2) Random Forest regressor\n",
    "    rf_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", RandomForestRegressor(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "    rf_grid = [{\n",
    "        \"model__n_estimators\": [100, 300],\n",
    "        \"model__max_depth\": [10, None],\n",
    "        \"model__min_samples_leaf\": [1, 5],\n",
    "    }]\n",
    "    candidates[\"random_forest\"] = (rf_pipe, rf_grid)\n",
    "\n",
    "    # 3) Support Vector Regressor (SVM)\n",
    "    svr_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"model\", SVR()),\n",
    "        ]\n",
    "    )\n",
    "    svr_grid = [{\n",
    "        \"model__C\": [0.1, 1.0, 10.0],\n",
    "        \"model__epsilon\": [0.01, 0.1],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"],\n",
    "        \"model__kernel\": [\"rbf\"],\n",
    "    }]\n",
    "    candidates[\"svr\"] = (svr_pipe, svr_grid)\n",
    "\n",
    "    # 4) Cluster-based Random Forest: add k-means cluster as feature\n",
    "    cluster_rf_pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"cluster\", ClusterFeatureAdder()),\n",
    "            (\"model\", RandomForestRegressor(\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "    cluster_rf_grid = [{\n",
    "        \"cluster__n_clusters\": [3, 5, 10],\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [10, None],\n",
    "    }]\n",
    "    candidates[\"cluster_rf\"] = (cluster_rf_pipe, cluster_rf_grid)\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def train_best_models_per_exchange(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = RANDOM_SEED,\n",
    ") -> Tuple[Dict[str, RegressorMixin], pd.DataFrame]:\n",
    "    \"\"\"Train multiple models per exchange and select the best by out-of-sample R².\n",
    "\n",
    "    Returns:\n",
    "        models: dict exchange -> best fitted pipeline\n",
    "        results: DataFrame with per-exchange, per-model metrics\n",
    "                 (R² train/test, MSE train/test, n_train, n_test)\n",
    "    \"\"\"\n",
    "    candidates = make_model_candidates(random_state=random_state)\n",
    "    models: Dict[str, RegressorMixin] = {}\n",
    "    results_rows: List[Dict] = []\n",
    "\n",
    "    for exch, d in df.groupby(GROUP_COL):\n",
    "        # Drop rows with missing features/target for this exchange\n",
    "        d_local = d.dropna(subset=FEATURE_COLS + [TARGET_COL])\n",
    "        if len(d_local) < 50:\n",
    "            # Not enough data to train robust models\n",
    "            continue\n",
    "\n",
    "        X = d_local[FEATURE_COLS].astype(\"float32\")\n",
    "        y = d_local[TARGET_COL].astype(\"float32\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        best_model_name: Optional[str] = None\n",
    "        best_model: Optional[RegressorMixin] = None\n",
    "        best_r2_test: float = float(\"-inf\")\n",
    "\n",
    "        for model_name, (pipe, param_grid) in candidates.items():\n",
    "            grid = GridSearchCV(\n",
    "                estimator=pipe,\n",
    "                param_grid=param_grid,\n",
    "                cv=3,\n",
    "                n_jobs=-1,\n",
    "                scoring=\"r2\",\n",
    "            )\n",
    "            grid.fit(X_train, y_train)\n",
    "\n",
    "            best_estimator = grid.best_estimator_\n",
    "\n",
    "            # In-sample and out-of-sample predictions\n",
    "            y_train_pred = best_estimator.predict(X_train)\n",
    "            y_test_pred = best_estimator.predict(X_test)\n",
    "\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            r2_test = r2_score(y_test, y_test_pred)\n",
    "            mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "            mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "            results_rows.append(\n",
    "                {\n",
    "                    \"exchange\": exch,\n",
    "                    \"model\": model_name,\n",
    "                    \"r2_train\": r2_train,\n",
    "                    \"r2_test\": r2_test,\n",
    "                    \"mse_train\": mse_train,\n",
    "                    \"mse_test\": mse_test,\n",
    "                    \"n_train\": len(X_train),\n",
    "                    \"n_test\": len(X_test),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Select best model for this exchange by highest test R²\n",
    "            if r2_test > best_r2_test:\n",
    "                best_r2_test = r2_test\n",
    "                best_model_name = model_name\n",
    "                best_model = best_estimator\n",
    "\n",
    "        if best_model is not None:\n",
    "            models[exch] = best_model\n",
    "            print(\n",
    "                f\"Best model for exchange {exch}: {best_model_name} \"\n",
    "                f\"(R² test = {best_r2_test:.3f})\"\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results_rows)\n",
    "    return models, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94c59f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonza\\AppData\\Local\\Temp\\ipykernel_24988\\3215556280.py:70: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes shape: (2274181, 8)\n",
      "Executions shape: (1161, 9)\n",
      "Merged features shape (before PI): (1161, 17)\n",
      "Merged features shape (after cleaning): (1142, 18)\n",
      "Best model for exchange ID1516: random_forest (R² test = 0.636)\n",
      "Best model for exchange ID29608: cluster_rf (R² test = 0.459)\n",
      "\n",
      "Per-exchange, per-model performance summary:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exchange",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "r2_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mse_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mse_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_train",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_test",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dd7d549d-4cf6-4c75-8046-25d0441a70c5",
       "rows": [
        [
         "1",
         "ID1516",
         "random_forest",
         "0.9757479052731016",
         "0.6360279254117738",
         "0.0010252428061786971",
         "0.00590810990905886",
         "860",
         "215"
        ],
        [
         "3",
         "ID1516",
         "cluster_rf",
         "0.9741944836528713",
         "0.6358659463673253",
         "0.001090912776506548",
         "0.005910739204173461",
         "860",
         "215"
        ],
        [
         "0",
         "ID1516",
         "linear",
         "0.4582147002220154",
         "0.2816247344017029",
         "0.022903649136424065",
         "0.011660895310342312",
         "860",
         "215"
        ],
        [
         "2",
         "ID1516",
         "svr",
         "0.23299111054516097",
         "-0.05672418466941487",
         "0.03242484226801696",
         "0.017153081410574433",
         "860",
         "215"
        ],
        [
         "7",
         "ID29608",
         "cluster_rf",
         "0.8967289716005163",
         "0.4592612506448689",
         "0.006365193779940617",
         "0.03337544816487937",
         "48",
         "13"
        ],
        [
         "5",
         "ID29608",
         "random_forest",
         "0.5416177929444739",
         "0.33497052056987",
         "0.02825275993087598",
         "0.04104691395855557",
         "48",
         "13"
        ],
        [
         "6",
         "ID29608",
         "svr",
         "0.17806405066037467",
         "0.054188369654044166",
         "0.0506606903536203",
         "0.05837733485901875",
         "48",
         "13"
        ],
        [
         "4",
         "ID29608",
         "linear",
         "0.7689478993415833",
         "-1.619523048400879",
         "0.014241084456443787",
         "0.16168203949928284",
         "48",
         "13"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exchange</th>\n",
       "      <th>model</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1516</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.975748</td>\n",
       "      <td>0.636028</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>860</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1516</td>\n",
       "      <td>cluster_rf</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.635866</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>860</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1516</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.458215</td>\n",
       "      <td>0.281625</td>\n",
       "      <td>0.022904</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>860</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1516</td>\n",
       "      <td>svr</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>-0.056724</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.017153</td>\n",
       "      <td>860</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID29608</td>\n",
       "      <td>cluster_rf</td>\n",
       "      <td>0.896729</td>\n",
       "      <td>0.459261</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.033375</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID29608</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.541618</td>\n",
       "      <td>0.334971</td>\n",
       "      <td>0.028253</td>\n",
       "      <td>0.041047</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID29608</td>\n",
       "      <td>svr</td>\n",
       "      <td>0.178064</td>\n",
       "      <td>0.054188</td>\n",
       "      <td>0.050661</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID29608</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.768948</td>\n",
       "      <td>-1.619523</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.161682</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  exchange          model  r2_train   r2_test  mse_train  mse_test  n_train  \\\n",
       "1   ID1516  random_forest  0.975748  0.636028   0.001025  0.005908      860   \n",
       "3   ID1516     cluster_rf  0.974194  0.635866   0.001091  0.005911      860   \n",
       "0   ID1516         linear  0.458215  0.281625   0.022904  0.011661      860   \n",
       "2   ID1516            svr  0.232991 -0.056724   0.032425  0.017153      860   \n",
       "7  ID29608     cluster_rf  0.896729  0.459261   0.006365  0.033375       48   \n",
       "5  ID29608  random_forest  0.541618  0.334971   0.028253  0.041047       48   \n",
       "6  ID29608            svr  0.178064  0.054188   0.050661  0.058377       48   \n",
       "4  ID29608         linear  0.768948 -1.619523   0.014241  0.161682       48   \n",
       "\n",
       "   n_test  \n",
       "1     215  \n",
       "3     215  \n",
       "0     215  \n",
       "2     215  \n",
       "7      13  \n",
       "5      13  \n",
       "6      13  \n",
       "4      13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved models to per_exchange_price_improvement_models.joblib\n"
     ]
    }
   ],
   "source": [
    "# 6. EXECUTION: LOAD DATA, TRAIN MODELS, REPORT METRICS, SAVE JOBLIB\n",
    "\n",
    "# 6.1 Load raw data\n",
    "quotes = load_quotes(QUOTES_PATH, KEEP_TICKERS)\n",
    "executions = load_executions(EXEC_PATH, KEEP_TICKERS)\n",
    "\n",
    "print(f\"Quotes shape: {quotes.shape}\")\n",
    "print(f\"Executions shape: {executions.shape}\")\n",
    "\n",
    "# 6.2 Merge executions with quotes and create features\n",
    "df_features = attach_quotes(executions, quotes)\n",
    "print(f\"Merged features shape (before PI): {df_features.shape}\")\n",
    "\n",
    "add_price_improvement(df_features)\n",
    "prepare_model_data(df_features)\n",
    "\n",
    "print(f\"Merged features shape (after cleaning): {df_features.shape}\")\n",
    "\n",
    "# 6.3 Train best models per exchange and get metrics\n",
    "models, results_df = train_best_models_per_exchange(df_features)\n",
    "\n",
    "print(\"\\nPer-exchange, per-model performance summary:\")\n",
    "display(results_df.sort_values([\"exchange\", \"r2_test\"], ascending=[True, False]))\n",
    "\n",
    "# 6.4 Save the chosen models (one per exchange) for use in somewhat_smart_order_router.py\n",
    "dump(models, \"per_exchange_price_improvement_models.joblib\")\n",
    "print(\"\\nSaved models to per_exchange_price_improvement_models.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "420f6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended exchange: ID29608\n",
      "Predicted price improvement: 0.34085572719573975\n",
      "Actual exchange: ID1516\n",
      "Actual price_improvement: 0.0023956299\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import somewhat_smart_order_router as ssor\n",
    "\n",
    "ssor = reload(ssor)\n",
    "\n",
    "row = df_features[df_features[\"exchange\"].isin([\"ID1516\", \"ID29608\"])].sample(1, random_state=1).iloc[0]\n",
    "side_char = \"B\" if row[\"side\"] == 1 else \"S\"\n",
    "\n",
    "router_args = {\n",
    "    \"symbol\":      str(row[\"symbol\"]),\n",
    "    \"side\":        side_char,\n",
    "    \"quantity\":    int(row[\"order_qty\"]),\n",
    "    \"limit_price\": float(row[\"limit_price\"]),\n",
    "    \"bid_price\":   float(row[\"bid_price\"]),\n",
    "    \"ask_price\":   float(row[\"ask_price\"]),\n",
    "    \"bid_size\":    int(row[\"bid_size\"]),\n",
    "    \"ask_size\":    int(row[\"ask_size\"]),\n",
    "}\n",
    "\n",
    "exchange, predicted_pi = ssor.best_price_improvement(**router_args)\n",
    "\n",
    "print(\"Recommended exchange:\", exchange)\n",
    "print(\"Predicted price improvement:\", predicted_pi)\n",
    "print(\"Actual exchange:\", row[\"exchange\"])\n",
    "print(\"Actual price_improvement:\", row[\"price_improvement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca0282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b941e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d818c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.13.7, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: c:\\Users\\gonza\\Documents\\UChicago\\Quarters\\Fall I\\FINM 32400 - Python for Financial Data Science\\assignment4_order_router\n",
      "plugins: anyio-4.11.0\n",
      "collected 3 items\n",
      "\n",
      "test_somewhat_smart_order_router.py \u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                  [100%]\u001b[0m\n",
      "\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m______________________________ test_normal_order ______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_normal_order\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Tests that a normal buy order returns a valid exchange\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       exchange, price_improvement = best_price_improvement(\u001b[90m\u001b[39;49;00m\n",
      "            symbol=\u001b[33m\"\u001b[39;49;00m\u001b[33mAAPL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            side=\u001b[33m\"\u001b[39;49;00m\u001b[33mB\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            quantity=\u001b[94m100\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            limit_price=\u001b[94m180.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            bid_price=\u001b[94m179.9\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ask_price=\u001b[94m180.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            bid_size=\u001b[94m500\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ask_size=\u001b[94m600\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_somewhat_smart_order_router.py\u001b[0m:9: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31msomewhat_smart_order_router.py\u001b[0m:74: in best_price_improvement\n",
      "    \u001b[0mmodels = _load_models()\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msomewhat_smart_order_router.py\u001b[0m:35: in _load_models\n",
      "    \u001b[0m_models = load(MODELS_PATH)\u001b[90m\u001b[39;49;00m\n",
      "              ^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m:749: in load\n",
      "    \u001b[0mobj = _unpickle(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m:626: in _unpickle\n",
      "    \u001b[0mobj = unpickler.load()\u001b[90m\u001b[39;49;00m\n",
      "          ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1256: in load\n",
      "    \u001b[0mdispatch[key[\u001b[94m0\u001b[39;49;00m]](\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1581: in load_stack_global\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.append(\u001b[96mself\u001b[39;49;00m.find_class(module, name))\u001b[90m\u001b[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1624: in find_class\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _getattribute(sys.modules[module], name)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "obj = <module '__main__' from 'C:\\\\Users\\\\gonza\\\\anaconda3\\\\envs\\\\Python-for-financial-data-science---HW1\\\\Scripts\\\\pytest.exe\\\\__main__.py'>\n",
      "name = 'ClusterFeatureAdder'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_getattribute\u001b[39;49;00m(obj, name):\u001b[90m\u001b[39;49;00m\n",
      "        top = obj\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m subpath \u001b[95min\u001b[39;49;00m name.split(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m subpath == \u001b[33m'\u001b[39;49;00m\u001b[33m<locals>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt get local attribute \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m on \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                     .format(name, top))\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                parent = obj\u001b[90m\u001b[39;49;00m\n",
      "                obj = \u001b[96mgetattr\u001b[39;49;00m(obj, subpath)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt get attribute \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m on \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                     .format(name, top)) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               AttributeError: Can't get attribute 'ClusterFeatureAdder' on <module '__main__' from 'C:\\\\Users\\\\gonza\\\\anaconda3\\\\envs\\\\Python-for-financial-data-science---HW1\\\\Scripts\\\\pytest.exe\\\\__main__.py'>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:326: AttributeError\n",
      "\u001b[31m\u001b[1m______________________________ test_corner_case _______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_corner_case\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Test that a small sell order still returns a valid exchange.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    This is a corner case with quantity 1 and minimal displayed size.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       exchange, price_improvement = best_price_improvement(\u001b[90m\u001b[39;49;00m\n",
      "            symbol=\u001b[33m\"\u001b[39;49;00m\u001b[33mAAPL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            side=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            quantity=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            limit_price=\u001b[94m180.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            bid_price=\u001b[94m179.9\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ask_price=\u001b[94m180.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            bid_size=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ask_size=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_somewhat_smart_order_router.py\u001b[0m:31: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31msomewhat_smart_order_router.py\u001b[0m:74: in best_price_improvement\n",
      "    \u001b[0mmodels = _load_models()\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msomewhat_smart_order_router.py\u001b[0m:35: in _load_models\n",
      "    \u001b[0m_models = load(MODELS_PATH)\u001b[90m\u001b[39;49;00m\n",
      "              ^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m:749: in load\n",
      "    \u001b[0mobj = _unpickle(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m:626: in _unpickle\n",
      "    \u001b[0mobj = unpickler.load()\u001b[90m\u001b[39;49;00m\n",
      "          ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1256: in load\n",
      "    \u001b[0mdispatch[key[\u001b[94m0\u001b[39;49;00m]](\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1581: in load_stack_global\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.append(\u001b[96mself\u001b[39;49;00m.find_class(module, name))\u001b[90m\u001b[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1624: in find_class\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _getattribute(sys.modules[module], name)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "obj = <module '__main__' from 'C:\\\\Users\\\\gonza\\\\anaconda3\\\\envs\\\\Python-for-financial-data-science---HW1\\\\Scripts\\\\pytest.exe\\\\__main__.py'>\n",
      "name = 'ClusterFeatureAdder'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_getattribute\u001b[39;49;00m(obj, name):\u001b[90m\u001b[39;49;00m\n",
      "        top = obj\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m subpath \u001b[95min\u001b[39;49;00m name.split(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m subpath == \u001b[33m'\u001b[39;49;00m\u001b[33m<locals>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt get local attribute \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m on \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                     .format(name, top))\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                parent = obj\u001b[90m\u001b[39;49;00m\n",
      "                obj = \u001b[96mgetattr\u001b[39;49;00m(obj, subpath)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt get attribute \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m on \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                     .format(name, top)) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               AttributeError: Can't get attribute 'ClusterFeatureAdder' on <module '__main__' from 'C:\\\\Users\\\\gonza\\\\anaconda3\\\\envs\\\\Python-for-financial-data-science---HW1\\\\Scripts\\\\pytest.exe\\\\__main__.py'>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:326: AttributeError\n",
      "\u001b[31m\u001b[1m_____________________________ test_corner_case_2 ______________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_corner_case_2\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Test that a price out of the range still returnsa recomendation\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       exchange, price_improvement = best_price_improvement(\u001b[90m\u001b[39;49;00m\n",
      "            symbol=\u001b[33m\"\u001b[39;49;00m\u001b[33mAAPL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            side=\u001b[33m\"\u001b[39;49;00m\u001b[33ms\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            quantity=\u001b[94m10\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            limit_price=\u001b[94m200.0\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            bid_price=\u001b[94m179.9\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ask_price=\u001b[94m180.1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            bid_size=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            ask_size=\u001b[94m1\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_somewhat_smart_order_router.py\u001b[0m:49: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31msomewhat_smart_order_router.py\u001b[0m:74: in best_price_improvement\n",
      "    \u001b[0mmodels = _load_models()\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31msomewhat_smart_order_router.py\u001b[0m:35: in _load_models\n",
      "    \u001b[0m_models = load(MODELS_PATH)\u001b[90m\u001b[39;49;00m\n",
      "              ^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m:749: in load\n",
      "    \u001b[0mobj = _unpickle(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m:626: in _unpickle\n",
      "    \u001b[0mobj = unpickler.load()\u001b[90m\u001b[39;49;00m\n",
      "          ^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1256: in load\n",
      "    \u001b[0mdispatch[key[\u001b[94m0\u001b[39;49;00m]](\u001b[96mself\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1581: in load_stack_global\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.append(\u001b[96mself\u001b[39;49;00m.find_class(module, name))\u001b[90m\u001b[39;49;00m\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:1624: in find_class\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m _getattribute(sys.modules[module], name)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "obj = <module '__main__' from 'C:\\\\Users\\\\gonza\\\\anaconda3\\\\envs\\\\Python-for-financial-data-science---HW1\\\\Scripts\\\\pytest.exe\\\\__main__.py'>\n",
      "name = 'ClusterFeatureAdder'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_getattribute\u001b[39;49;00m(obj, name):\u001b[90m\u001b[39;49;00m\n",
      "        top = obj\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m subpath \u001b[95min\u001b[39;49;00m name.split(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m subpath == \u001b[33m'\u001b[39;49;00m\u001b[33m<locals>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt get local attribute \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m on \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                     .format(name, top))\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                parent = obj\u001b[90m\u001b[39;49;00m\n",
      "                obj = \u001b[96mgetattr\u001b[39;49;00m(obj, subpath)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mexcept\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mt get attribute \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m on \u001b[39;49;00m\u001b[33m{!r}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                     .format(name, top)) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               AttributeError: Can't get attribute 'ClusterFeatureAdder' on <module '__main__' from 'C:\\\\Users\\\\gonza\\\\anaconda3\\\\envs\\\\Python-for-financial-data-science---HW1\\\\Scripts\\\\pytest.exe\\\\__main__.py'>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\gonza\\anaconda3\\envs\\Python-for-financial-data-science---HW1\\Lib\\pickle.py\u001b[0m:326: AttributeError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_somewhat_smart_order_router.py::\u001b[1mtest_normal_order\u001b[0m - AttributeError: Can't get attribute 'ClusterFeatureAdder' on <module '__mai...\n",
      "\u001b[31mFAILED\u001b[0m test_somewhat_smart_order_router.py::\u001b[1mtest_corner_case\u001b[0m - AttributeError: Can't get attribute 'ClusterFeatureAdder' on <module '__mai...\n",
      "\u001b[31mFAILED\u001b[0m test_somewhat_smart_order_router.py::\u001b[1mtest_corner_case_2\u001b[0m - AttributeError: Can't get attribute 'ClusterFeatureAdder' on <module '__mai...\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m3 failed\u001b[0m\u001b[31m in 4.51s\u001b[0m\u001b[31m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_somewhat_smart_order_router.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-for-financial-data-science---HW1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
